{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Previs\u00e3o de Riscos Card\u00edacos Bem-vindo \u00e0 documenta\u00e7\u00e3o do projeto de an\u00e1lise de dados e classifica\u00e7\u00e3o de doen\u00e7as card\u00edacas. Este projeto utiliza v\u00e1rias bibliotecas de aprendizado de m\u00e1quina para analisar e prever a presen\u00e7a de doen\u00e7as card\u00edacas com base em um conjunto de dados. Aquisi\u00e7\u00e3o de bibliotecas e dados necess\u00e1rios ao projeto. Nesta se\u00e7\u00e3o, ser\u00e1 importado todas as bibliotecas utilizadas durante o projeto, al\u00e9m do arquivo csv com os dados de treinamento. Importa\u00e7\u00e3o das Bibliotecas Aqui, estamos importando todas as bibliotecas necess\u00e1rias para manipula\u00e7\u00e3o de dados, visualiza\u00e7\u00e3o e aprendizado de m\u00e1quina. import pandas as pd import matplotlib.pyplot as plt import seaborn as sns from sklearn.preprocessing import RobustScaler, LabelEncoder from sklearn.model_selection import train_test_split, cross_val_score from sklearn.linear_model import LogisticRegression from sklearn.neighbors import KNeighborsClassifier from sklearn.tree import DecisionTreeClassifier from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier from sklearn.naive_bayes import GaussianNB from sklearn.model_selection import train_test_split, GridSearchCV from sklearn.metrics import accuracy_score, f1_score, make_scorer Carregamento dos Dados Carregamos o conjunto de dados heart.csv e configuramos o pandas para mostrar todas as linhas ao imprimir o DataFrame. df = pd.read_csv(\"./heart.csv\") pd.set_option('display.max_rows', None) Verifica\u00e7\u00e3o dos Dados Imprimimos o DataFrame, verificamos os tipos de dados, informa\u00e7\u00f5es gerais e a presen\u00e7a de valores nulos. O comando dtypes mostra os tipos de dados em cada coluna do DataFrame. df.info() fornece informa\u00e7\u00f5es gerais sobre o DataFrame, incluindo o n\u00famero de entradas n\u00e3o nulas em cada coluna. df.isnull().sum() retorna a contagem de valores nulos em cada coluna do DataFrame. df.dtypes df.info() df.isnull().sum() An\u00e1lise Explorat\u00f3ria Nessa fase, analisamos as distribui\u00e7\u00f5es das colunas do conjunto de dados. Esse c\u00f3digo gera um gr\u00e1fico de barras para a coluna output . Repetimos o processo para outras colunas categ\u00f3ricas ( sex , cp , fbs , restecg , exng , slp , thall ). Output plt.figure(figsize=(8, 6)) column = \"output\" df[column].value_counts().plot(kind='bar', color='skyblue') plt.title(f'Contagem de valores em {column}') plt.xlabel(column) plt.ylabel('Contagem') plt.xticks(rotation=0) plt.show() Figura 1 - Valores da coluna output. Sex plt.figure(figsize=(8, 6)) column = \"sex\" df[column].value_counts().plot(kind='bar', color='skyblue') plt.title(f'Contagem de valores em {column}') plt.xlabel(column) plt.ylabel('Contagem') plt.xticks(rotation=0) plt.show() Figura 2 - Valores da coluna sex. CP plt.figure(figsize=(8, 6)) column = \"cp\" df[column].value_counts().plot(kind='bar', color='skyblue') plt.title(f'Contagem de valores em {column}') plt.xlabel(column) plt.ylabel('Contagem') plt.xticks(rotation=0) plt.show() Figura 3 - Valores da coluna cp. FBS plt.figure(figsize=(8, 6)) column = \"fbs\" df[column].value_counts().plot(kind='bar', color='skyblue') plt.title(f'Contagem de valores em {column}') plt.xlabel(column) plt.ylabel('Contagem') plt.xticks(rotation=0) plt.show() Figura 4 - Valores da coluna fbs. RESTECG plt.figure(figsize=(8, 6)) column = \"restecg\" df[column].value_counts().plot(kind='bar', color='skyblue') plt.title(f'Contagem de valores em {column}') plt.xlabel(column) plt.ylabel('Contagem') plt.xticks(rotation=0) plt.show() Figura 5 - Valores da coluna restecg. EXNG plt.figure(figsize=(8, 6)) column = \"exng\" df[column].value_counts().plot(kind='bar', color='skyblue') plt.title(f'Contagem de valores em {column}') plt.xlabel(column) plt.ylabel('Contagem') plt.xticks(rotation=0) plt.show() Figura 6 - Valores da coluna exng. SLP plt.figure(figsize=(8, 6)) column = \"slp\" df[column].value_counts().plot(kind='bar', color='skyblue') plt.title(f'Contagem de valores em {column}') plt.xlabel(column) plt.ylabel('Contagem') plt.xticks(rotation=0) plt.show() Figura 7 - Valores da coluna slp. THALL plt.figure(figsize=(8, 6)) column = \"thall\" df[column].value_counts().plot(kind='bar', color='skyblue') plt.title(f'Contagem de valores em {column}') plt.xlabel(column) plt.ylabel('Contagem') plt.xticks(rotation=0) plt.show() Figura 8 - Valores da coluna thall. Distribui\u00e7\u00e3o normal de todas as colunas Observa-se a necessidade de normalizar os dados, devido a muitas features n\u00e3o estarem na distribuicao normal. plt.figure(figsize=(20, 15)) for grafico, feature in enumerate(df.columns, 1): plt.subplot(5, 3, grafico) plt.title(f\"Distribui\u00e7\u00e3o dos dados da coluna {feature}\") sns.histplot(df[feature], kde=True) plt.tight_layout() plt.plot() Figura 9 - Distribui\u00e7\u00e3o normal de todas as colunas. Prepara\u00e7\u00e3o dos Dados Nessa fase, os dados ser\u00e3o preparados para a modelagem de aprendizado de m\u00e1quina. Ser\u00e1 realizado a limpeza dos dados, tratando valores, corre\u00e7\u00e3o de outliers, codifica\u00e7\u00e3o de vari\u00e1veis categ\u00f3ricas e normaliza\u00e7\u00e3o. Normaliza\u00e7\u00e3o dos Dados Aqui, os dados ser\u00e3o normalizados usando RobustScaler e aplicamos get_dummies para transformar colunas categ\u00f3ricas em vari\u00e1veis dummy. categorias = ['sex','exng','caa','cp','fbs','restecg','slp','thall'] valores_numericos = ['age','trtbps','chol','thalachh','oldpeak'] df = pd.get_dummies(df, columns=categorias, drop_first=True) X = df.drop(['output'], axis=1) y = df[['output']] y = y.values.reshape(-1) rs = RobustScaler() X[valores_numericos] = rs.fit_transform(X[valores_numericos]) Visualiza\u00e7\u00e3o dos Dados Normalizados Visualizamos a distribui\u00e7\u00e3o das colunas ap\u00f3s a normaliza\u00e7\u00e3o. plt.figure(figsize=(15, 20)) for grafico, feature in enumerate(df.columns, 1): plt.subplot(10, 3, grafico) plt.title(f\"Distribui\u00e7\u00e3o dos dados da coluna {feature}\") sns.histplot(df[feature], kde=True) plt.tight_layout() plt.plot() Figura 10 - Distribui\u00e7\u00e3o das colunas ap\u00f3s normaliza\u00e7\u00e3o. Separa\u00e7\u00e3o dos Dados Separamos os dados em conjuntos de treinamento e teste. X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) Treinamento de Modelos Definimos uma lista de modelos para serem avaliados. Ap\u00f3s uma pesquisa em grupo, foi selecionado uma lista de modelos de classifica\u00e7\u00e3o bin\u00e1ria que se adequavam ao problema a ser resolvido, sendo eles Logistic Regression , Gradient Boosting , KNeighbors Classifier , Decision Tree Classifier , Random Forest , Naive Bayes Classifier . Lista de Modelos models = [ ('Logistic Regression', LogisticRegression(random_state=42)), ('Gradient Boosting', GradientBoostingClassifier(random_state=42)), ('KNeighbors Classifier', KNeighborsClassifier()), ('Decision Tree Classifier', DecisionTreeClassifier(random_state=42)), ('Random Forest', RandomForestClassifier(random_state=42)), ('Naive Bayes Classifier', GaussianNB()) ] Treinamento e Avalia\u00e7\u00e3o dos Modelos Neste trecho do c\u00f3digo, treinamos cada modelo, calculamos a acur\u00e1cia e o F1-score, e determinamos o melhor modelo com base nessas m\u00e9tricas. best_f1_model = None f1 = 0.0 best_f1_score = 0.0 best_accuracy_model = None accuracy = 0.0 best_accuracy = 0.0 for name, model in models: model.fit(X_train, y_train) y_pred = model.predict(X_test) accuracy = accuracy_score(y_test, y_pred) f1 = f1_score(y_test, y_pred) print(\"Model: \", name) print(\"Accuracy: \", accuracy) print(\"F1-Score: \", f1, \"\\n\") if f1 > best_f1_score: best_f1_score = f1 best_f1_model = name if accuracy > best_accuracy: best_accuracy = accuracy best_accuracy_model = name print(\"Best Model by F1-Score: \", best_f1_model) print(\"Best Model by Accuracy: \", best_accuracy_model) Verificou-se que os algoritmos regress\u00e3o log\u00edstica e KNeighbors e obteveram os melhores resultados de acur\u00e1cia e F1-Score. Destacando o algoritmo de regress\u00e3o log\u00edstica que se mostrou muito promissor. Figura 11 - Resultado do treinamento. Ajuste de Hiperpar\u00e2metros Nesta se\u00e7\u00e3o, \u00e9 realizado o ajuste de hiperpar\u00e2metros para melhorar o desempenho dos modelos. Para cada modelo, foram levantados os hiperpar\u00e2metros mais promissores visando aumentar o desempenho dos mesmos Em seguida, foi aplicado o m\u00e9todo de valida\u00e7\u00e3o cruzada, dividindo o conjunto de dados em cinco partes para evitar o overfitting Ajuste de Hiperpar\u00e2metros com GridSearchCV Neste trecho, usamos GridSearchCV para encontrar os melhores par\u00e2metros para cada modelo, maximizando o F1-score. new_models = [ ('Logistic Regression', LogisticRegression(random_state=42)), ('Gradient Boosting', GradientBoostingClassifier(random_state=42)), ('KNeighbors Classifier', KNeighborsClassifier()), ('Decision Tree Classifier', DecisionTreeClassifier(random_state=42)), ('Random Forest', RandomForestClassifier(random_state=42)), ('Naive Bayes Classifier', GaussianNB()) ] def hyperparameter_tuning(X_train, X_test, y_train, y_test, models): results = {} for model_name, model in models: param_grid = {} if model_name == 'Logistic Regression': param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]} elif model_name == 'KNeighbors Classifier': param_grid = {'n_neighbors': [3, 5, 7, 9]} elif model_name == 'Naive Bayes Classifier': param_grid = {'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6]} elif model_name == 'Decision Tree Classifier': param_grid = {'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10]} elif model_name == 'Random Forest': param_grid = {'n_estimators': [100, 200, 300], 'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10]} elif model_name == 'Gradient Boosting': param_grid = {'learning_rate': [0.01, 0.1, 0.2], 'n_estimators': [100, 200, 300], 'max_depth': [3, 5, 7]} scoring = {'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average='macro')} grid_search = GridSearchCV(model, param_grid, cv=5, scoring=scoring, refit='F1') grid_search.fit(X_train, y_train) best_params = grid_search.best_params_ best_model = grid_search.best_estimator_ test_accuracy = best_model.score(X_test, y_test) y_pred = best_model.predict(X_test) test_f1 = f1_score(y_test, y_pred, average='macro') results[model_name] = { 'best_params': best_params, 'validation_accuracy': grid_search.cv_results_['mean_test_Accuracy'][grid_search.best_index_], 'validation_f1': grid_search.cv_results_['mean_test_F1'][grid_search.best_index_], 'test_accuracy': test_accuracy, 'test_f1': test_f1, } return results results = hyperparameter_tuning(X_train, X_test, y_train, y_test, new_models) Em seguida, visualizamos os resultados. for model_name, info in results.items(): print(f\"Model: {model_name}\") print(f\"Best Parameters: {info['best_params']}\") print(f\"Validation Accuracy: {info['validation_accuracy']:.4f}\") print(f\"Validation F1: {info['validation_f1']:.4f}\") print(f\"Test Accuracy: {info['test_accuracy']:.4f}\") print(f\"Test F1: {info['test_f1']:.4f}\") print(\"-\" * 40) Figura 12 - Resultado do treinamento ap\u00f3s ajuste de hiperpar\u00e2metros. Resultado Entre os modelos avaliados, o Logistic Regression apresentou o melhor desempenho geral, com uma acur\u00e1cia de 0.8204 e um score F1 de 0.8462, indicando um excelente equil\u00edbrio entre precis\u00e3o e recall. Bibliografia Janosi,Andras, Steinbrunn,William, Pfisterer,Matthias, and Detrano,Robert. (1988). Heart Disease. UCI Machine Learning Repository. https://doi.org/10.24432/C52P4X .","title":"Previs\u00e3o de Riscos Card\u00edacos"},{"location":"#previsao-de-riscos-cardiacos","text":"Bem-vindo \u00e0 documenta\u00e7\u00e3o do projeto de an\u00e1lise de dados e classifica\u00e7\u00e3o de doen\u00e7as card\u00edacas. Este projeto utiliza v\u00e1rias bibliotecas de aprendizado de m\u00e1quina para analisar e prever a presen\u00e7a de doen\u00e7as card\u00edacas com base em um conjunto de dados.","title":"Previs\u00e3o de Riscos Card\u00edacos"},{"location":"#aquisicao-de-bibliotecas-e-dados-necessarios-ao-projeto","text":"Nesta se\u00e7\u00e3o, ser\u00e1 importado todas as bibliotecas utilizadas durante o projeto, al\u00e9m do arquivo csv com os dados de treinamento.","title":"Aquisi\u00e7\u00e3o de bibliotecas e dados necess\u00e1rios ao projeto."},{"location":"#importacao-das-bibliotecas","text":"Aqui, estamos importando todas as bibliotecas necess\u00e1rias para manipula\u00e7\u00e3o de dados, visualiza\u00e7\u00e3o e aprendizado de m\u00e1quina. import pandas as pd import matplotlib.pyplot as plt import seaborn as sns from sklearn.preprocessing import RobustScaler, LabelEncoder from sklearn.model_selection import train_test_split, cross_val_score from sklearn.linear_model import LogisticRegression from sklearn.neighbors import KNeighborsClassifier from sklearn.tree import DecisionTreeClassifier from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier from sklearn.naive_bayes import GaussianNB from sklearn.model_selection import train_test_split, GridSearchCV from sklearn.metrics import accuracy_score, f1_score, make_scorer","title":"Importa\u00e7\u00e3o das Bibliotecas"},{"location":"#carregamento-dos-dados","text":"Carregamos o conjunto de dados heart.csv e configuramos o pandas para mostrar todas as linhas ao imprimir o DataFrame. df = pd.read_csv(\"./heart.csv\") pd.set_option('display.max_rows', None)","title":"Carregamento dos Dados"},{"location":"#verificacao-dos-dados","text":"Imprimimos o DataFrame, verificamos os tipos de dados, informa\u00e7\u00f5es gerais e a presen\u00e7a de valores nulos. O comando dtypes mostra os tipos de dados em cada coluna do DataFrame. df.info() fornece informa\u00e7\u00f5es gerais sobre o DataFrame, incluindo o n\u00famero de entradas n\u00e3o nulas em cada coluna. df.isnull().sum() retorna a contagem de valores nulos em cada coluna do DataFrame. df.dtypes df.info() df.isnull().sum()","title":"Verifica\u00e7\u00e3o dos Dados"},{"location":"#analise-exploratoria","text":"Nessa fase, analisamos as distribui\u00e7\u00f5es das colunas do conjunto de dados. Esse c\u00f3digo gera um gr\u00e1fico de barras para a coluna output . Repetimos o processo para outras colunas categ\u00f3ricas ( sex , cp , fbs , restecg , exng , slp , thall ).","title":"An\u00e1lise Explorat\u00f3ria"},{"location":"#output","text":"plt.figure(figsize=(8, 6)) column = \"output\" df[column].value_counts().plot(kind='bar', color='skyblue') plt.title(f'Contagem de valores em {column}') plt.xlabel(column) plt.ylabel('Contagem') plt.xticks(rotation=0) plt.show() Figura 1 - Valores da coluna output.","title":"Output"},{"location":"#sex","text":"plt.figure(figsize=(8, 6)) column = \"sex\" df[column].value_counts().plot(kind='bar', color='skyblue') plt.title(f'Contagem de valores em {column}') plt.xlabel(column) plt.ylabel('Contagem') plt.xticks(rotation=0) plt.show() Figura 2 - Valores da coluna sex.","title":"Sex"},{"location":"#cp","text":"plt.figure(figsize=(8, 6)) column = \"cp\" df[column].value_counts().plot(kind='bar', color='skyblue') plt.title(f'Contagem de valores em {column}') plt.xlabel(column) plt.ylabel('Contagem') plt.xticks(rotation=0) plt.show() Figura 3 - Valores da coluna cp.","title":"CP"},{"location":"#fbs","text":"plt.figure(figsize=(8, 6)) column = \"fbs\" df[column].value_counts().plot(kind='bar', color='skyblue') plt.title(f'Contagem de valores em {column}') plt.xlabel(column) plt.ylabel('Contagem') plt.xticks(rotation=0) plt.show() Figura 4 - Valores da coluna fbs.","title":"FBS"},{"location":"#restecg","text":"plt.figure(figsize=(8, 6)) column = \"restecg\" df[column].value_counts().plot(kind='bar', color='skyblue') plt.title(f'Contagem de valores em {column}') plt.xlabel(column) plt.ylabel('Contagem') plt.xticks(rotation=0) plt.show() Figura 5 - Valores da coluna restecg.","title":"RESTECG"},{"location":"#exng","text":"plt.figure(figsize=(8, 6)) column = \"exng\" df[column].value_counts().plot(kind='bar', color='skyblue') plt.title(f'Contagem de valores em {column}') plt.xlabel(column) plt.ylabel('Contagem') plt.xticks(rotation=0) plt.show() Figura 6 - Valores da coluna exng.","title":"EXNG"},{"location":"#slp","text":"plt.figure(figsize=(8, 6)) column = \"slp\" df[column].value_counts().plot(kind='bar', color='skyblue') plt.title(f'Contagem de valores em {column}') plt.xlabel(column) plt.ylabel('Contagem') plt.xticks(rotation=0) plt.show() Figura 7 - Valores da coluna slp.","title":"SLP"},{"location":"#thall","text":"plt.figure(figsize=(8, 6)) column = \"thall\" df[column].value_counts().plot(kind='bar', color='skyblue') plt.title(f'Contagem de valores em {column}') plt.xlabel(column) plt.ylabel('Contagem') plt.xticks(rotation=0) plt.show() Figura 8 - Valores da coluna thall.","title":"THALL"},{"location":"#distribuicao-normal-de-todas-as-colunas","text":"Observa-se a necessidade de normalizar os dados, devido a muitas features n\u00e3o estarem na distribuicao normal. plt.figure(figsize=(20, 15)) for grafico, feature in enumerate(df.columns, 1): plt.subplot(5, 3, grafico) plt.title(f\"Distribui\u00e7\u00e3o dos dados da coluna {feature}\") sns.histplot(df[feature], kde=True) plt.tight_layout() plt.plot() Figura 9 - Distribui\u00e7\u00e3o normal de todas as colunas.","title":"Distribui\u00e7\u00e3o normal de todas as colunas"},{"location":"#preparacao-dos-dados","text":"Nessa fase, os dados ser\u00e3o preparados para a modelagem de aprendizado de m\u00e1quina. Ser\u00e1 realizado a limpeza dos dados, tratando valores, corre\u00e7\u00e3o de outliers, codifica\u00e7\u00e3o de vari\u00e1veis categ\u00f3ricas e normaliza\u00e7\u00e3o.","title":"Prepara\u00e7\u00e3o dos Dados"},{"location":"#normalizacao-dos-dados","text":"Aqui, os dados ser\u00e3o normalizados usando RobustScaler e aplicamos get_dummies para transformar colunas categ\u00f3ricas em vari\u00e1veis dummy. categorias = ['sex','exng','caa','cp','fbs','restecg','slp','thall'] valores_numericos = ['age','trtbps','chol','thalachh','oldpeak'] df = pd.get_dummies(df, columns=categorias, drop_first=True) X = df.drop(['output'], axis=1) y = df[['output']] y = y.values.reshape(-1) rs = RobustScaler() X[valores_numericos] = rs.fit_transform(X[valores_numericos])","title":"Normaliza\u00e7\u00e3o dos Dados"},{"location":"#visualizacao-dos-dados-normalizados","text":"Visualizamos a distribui\u00e7\u00e3o das colunas ap\u00f3s a normaliza\u00e7\u00e3o. plt.figure(figsize=(15, 20)) for grafico, feature in enumerate(df.columns, 1): plt.subplot(10, 3, grafico) plt.title(f\"Distribui\u00e7\u00e3o dos dados da coluna {feature}\") sns.histplot(df[feature], kde=True) plt.tight_layout() plt.plot() Figura 10 - Distribui\u00e7\u00e3o das colunas ap\u00f3s normaliza\u00e7\u00e3o.","title":"Visualiza\u00e7\u00e3o dos Dados Normalizados"},{"location":"#separacao-dos-dados","text":"Separamos os dados em conjuntos de treinamento e teste. X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","title":"Separa\u00e7\u00e3o dos Dados"},{"location":"#treinamento-de-modelos","text":"Definimos uma lista de modelos para serem avaliados. Ap\u00f3s uma pesquisa em grupo, foi selecionado uma lista de modelos de classifica\u00e7\u00e3o bin\u00e1ria que se adequavam ao problema a ser resolvido, sendo eles Logistic Regression , Gradient Boosting , KNeighbors Classifier , Decision Tree Classifier , Random Forest , Naive Bayes Classifier .","title":"Treinamento de Modelos"},{"location":"#lista-de-modelos","text":"models = [ ('Logistic Regression', LogisticRegression(random_state=42)), ('Gradient Boosting', GradientBoostingClassifier(random_state=42)), ('KNeighbors Classifier', KNeighborsClassifier()), ('Decision Tree Classifier', DecisionTreeClassifier(random_state=42)), ('Random Forest', RandomForestClassifier(random_state=42)), ('Naive Bayes Classifier', GaussianNB()) ]","title":"Lista de Modelos"},{"location":"#treinamento-e-avaliacao-dos-modelos","text":"Neste trecho do c\u00f3digo, treinamos cada modelo, calculamos a acur\u00e1cia e o F1-score, e determinamos o melhor modelo com base nessas m\u00e9tricas. best_f1_model = None f1 = 0.0 best_f1_score = 0.0 best_accuracy_model = None accuracy = 0.0 best_accuracy = 0.0 for name, model in models: model.fit(X_train, y_train) y_pred = model.predict(X_test) accuracy = accuracy_score(y_test, y_pred) f1 = f1_score(y_test, y_pred) print(\"Model: \", name) print(\"Accuracy: \", accuracy) print(\"F1-Score: \", f1, \"\\n\") if f1 > best_f1_score: best_f1_score = f1 best_f1_model = name if accuracy > best_accuracy: best_accuracy = accuracy best_accuracy_model = name print(\"Best Model by F1-Score: \", best_f1_model) print(\"Best Model by Accuracy: \", best_accuracy_model) Verificou-se que os algoritmos regress\u00e3o log\u00edstica e KNeighbors e obteveram os melhores resultados de acur\u00e1cia e F1-Score. Destacando o algoritmo de regress\u00e3o log\u00edstica que se mostrou muito promissor. Figura 11 - Resultado do treinamento.","title":"Treinamento e Avalia\u00e7\u00e3o dos Modelos"},{"location":"#ajuste-de-hiperparametros","text":"Nesta se\u00e7\u00e3o, \u00e9 realizado o ajuste de hiperpar\u00e2metros para melhorar o desempenho dos modelos. Para cada modelo, foram levantados os hiperpar\u00e2metros mais promissores visando aumentar o desempenho dos mesmos Em seguida, foi aplicado o m\u00e9todo de valida\u00e7\u00e3o cruzada, dividindo o conjunto de dados em cinco partes para evitar o overfitting","title":"Ajuste de Hiperpar\u00e2metros"},{"location":"#ajuste-de-hiperparametros-com-gridsearchcv","text":"Neste trecho, usamos GridSearchCV para encontrar os melhores par\u00e2metros para cada modelo, maximizando o F1-score. new_models = [ ('Logistic Regression', LogisticRegression(random_state=42)), ('Gradient Boosting', GradientBoostingClassifier(random_state=42)), ('KNeighbors Classifier', KNeighborsClassifier()), ('Decision Tree Classifier', DecisionTreeClassifier(random_state=42)), ('Random Forest', RandomForestClassifier(random_state=42)), ('Naive Bayes Classifier', GaussianNB()) ] def hyperparameter_tuning(X_train, X_test, y_train, y_test, models): results = {} for model_name, model in models: param_grid = {} if model_name == 'Logistic Regression': param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]} elif model_name == 'KNeighbors Classifier': param_grid = {'n_neighbors': [3, 5, 7, 9]} elif model_name == 'Naive Bayes Classifier': param_grid = {'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6]} elif model_name == 'Decision Tree Classifier': param_grid = {'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10]} elif model_name == 'Random Forest': param_grid = {'n_estimators': [100, 200, 300], 'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10]} elif model_name == 'Gradient Boosting': param_grid = {'learning_rate': [0.01, 0.1, 0.2], 'n_estimators': [100, 200, 300], 'max_depth': [3, 5, 7]} scoring = {'Accuracy': make_scorer(accuracy_score), 'F1': make_scorer(f1_score, average='macro')} grid_search = GridSearchCV(model, param_grid, cv=5, scoring=scoring, refit='F1') grid_search.fit(X_train, y_train) best_params = grid_search.best_params_ best_model = grid_search.best_estimator_ test_accuracy = best_model.score(X_test, y_test) y_pred = best_model.predict(X_test) test_f1 = f1_score(y_test, y_pred, average='macro') results[model_name] = { 'best_params': best_params, 'validation_accuracy': grid_search.cv_results_['mean_test_Accuracy'][grid_search.best_index_], 'validation_f1': grid_search.cv_results_['mean_test_F1'][grid_search.best_index_], 'test_accuracy': test_accuracy, 'test_f1': test_f1, } return results results = hyperparameter_tuning(X_train, X_test, y_train, y_test, new_models) Em seguida, visualizamos os resultados. for model_name, info in results.items(): print(f\"Model: {model_name}\") print(f\"Best Parameters: {info['best_params']}\") print(f\"Validation Accuracy: {info['validation_accuracy']:.4f}\") print(f\"Validation F1: {info['validation_f1']:.4f}\") print(f\"Test Accuracy: {info['test_accuracy']:.4f}\") print(f\"Test F1: {info['test_f1']:.4f}\") print(\"-\" * 40) Figura 12 - Resultado do treinamento ap\u00f3s ajuste de hiperpar\u00e2metros.","title":"Ajuste de Hiperpar\u00e2metros com GridSearchCV"},{"location":"#resultado","text":"Entre os modelos avaliados, o Logistic Regression apresentou o melhor desempenho geral, com uma acur\u00e1cia de 0.8204 e um score F1 de 0.8462, indicando um excelente equil\u00edbrio entre precis\u00e3o e recall.","title":"Resultado"},{"location":"#bibliografia","text":"Janosi,Andras, Steinbrunn,William, Pfisterer,Matthias, and Detrano,Robert. (1988). Heart Disease. UCI Machine Learning Repository. https://doi.org/10.24432/C52P4X .","title":"Bibliografia"}]}